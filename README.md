# Awesome LLM Security Paper

---

![Academic Alpaca](resources/DALLÂ·E%202024-07-30%2015.10.44%20-%20An%20academic-looking%20alpaca%20wearing%20scholarly%20glasses%20and%20a%20graduation%20cap%2C%20with%20an%20intellectual%20and%20serious%20expression.%20The%20background%20should%20be%20a%20lib.webp)

**Languages: [English](README.md) | [ä¸­æ–‡](README_zh.md)**

ğŸ‰ğŸ‰ğŸ‰ **Welcome to the LLM Security Research Repository, your premier destination for the latest and most comprehensive research on LLM security ! ! !**

As the field of artificial intelligence rapidly evolves, so do the security challenges associated with large models. Our repository is at the forefront of this emerging discipline, providing a comprehensive and constantly updated collection of research papers. Our repository stands out for several key reasons:

- ğŸ”¥ **Cutting-Edge Security Research**: Focused on the newest and most innovative security studies targeting large language models, ensuring you stay ahead in this critical area.

- â°ï¸ **Real-Time Updates**: Our repository is updated in real-time, offering the most current and relevant research findings as they become available.

- ğŸ“šï¸ **Comprehensive Coverage**: We aim to cover all aspects of large model security, from theoretical foundations to practical applications, and our collection will continually expand to include every facet of this essential field.

- ğŸ‡¨ğŸ‡³ **High-Quality Bilingual Content**: Access high-quality articles in both Chinese and English, catering to a global audience and promoting cross-language collaboration.

Join us in exploring the cutting-edge of AI security and contribute to a safer future for large models. Dive into our extensive and ever-growing collection of research papers today, stay ahead in the rapidly evolving field of AI model security ! ! !

# Data extraction & privacy

| Title | Date | Published |
|-------|------|-----------|
| [Bag of Tricks for Training Data Extraction from Language Models](paper_list/Bag_of_Tricks_for_Training_Data_Extraction_from_Language_Models.md) | 2023.2.9 | arXiv |

# Contributing
your contributions are always welcome!

If you have any questions about this paper list, or seek academic research in the field of LLM security, please get in touch at yaojialzc@gmail.com.
